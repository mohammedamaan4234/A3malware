from tkinter import messagebox
from tkinter import *
from tkinter.filedialog import askopenfilename
from tkinter import simpledialog
import tkinter 
import numpy as np
from tkinter import filedialog
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.naive_bayes import BernoulliNB
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import accuracy_score
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn import svm
from keras.models import Sequential
from keras.layers import Convolution2D
from keras.layers import MaxPooling2D
from keras.layers import Flatten
from keras.layers import Dense, Activation, BatchNormalization, Dropout
from sklearn.preprocessing import OneHotEncoder
from keras.models import model_from_json
from keras.layers import LSTM
from keras.layers import Embedding
#from keras.layers.embeddings import Embedding
import keras
import tensorflow as tf
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, LSTM, Dropout, Activation
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score





from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import Normalizer
import keras.layers
from keras.models import model_from_json

main = tkinter.Tk() #Dialog window (create app window)
main.title("Robust Intelligent Malware Detection Using Deep Learning") #webapp title
main.geometry("1300x1200") #web app size

malware_name = ['Dialer Adialer.C', 'Backdoor Agent.FYI', 'Worm Allaple.A', 'Worm Allaple.L', 'Trojan Alueron.gen',
                'Worm:AutoIT Autorun.K',
                'Trojan C2Lop.P', 'Trojan C2Lop.gen', 'Dialer Dialplatform.B', 'Trojan Downloader Dontovo.A',
                'Rogue Fakerean', 'Dialer Instantaccess',
                'PWS Lolyda.AA 1', 'PWS Lolyda.AA 2', 'PWS Lolyda.AA 3', 'PWS Lolyda.AT', 'Trojan Malex.gen',
                'Trojan Downloader Obfuscator.AD',
                'Backdoor Rbot!gen', 'Trojan Skintrim.N', 'Trojan Downloader Swizzor.gen!E',
                'Trojan Downloader Swizzor.gen!I', 'Worm VB.AT',
                'Trojan Downloader Wintrim.BX', 'Worm Yuner.A'] #list
#global variable decleration
global filename
global knn_precision, nb_precision, tree_precision, svm_precision, random_precision, cnn_precision, lstm_precision
global knn_recall, nb_recall, tree_recall, svm_recall, random_recall, cnn_recall, lstm_recall
global knn_fmeasure, nb_fmeasure, tree_fmeasure, svm_fmeasure, random_fmeasure, cnn_fmeasure, lstm_fmeasure
global knn_acc, nb_acc, tree_acc, svm_acc, random_acc, cnn_acc, lstm_acc

global classifier
global X_train, X_test, y_train, y_test


def load_lstmcnn(dataset, standardize=True):
    features = dataset['arr'][:, 0]
    features = np.array([feature for feature in features])
    features = np.reshape(features, (features.shape[0], features.shape[1] * features.shape[2]))
    if standardize:
        features = StandardScaler().fit_transform(features)

    labels = dataset['arr'][:, 1]
    labels = np.array([label for label in labels])

    print(labels.shape)
    print(features.shape)

    return features, labels

# fits and shapes the dataset for prediction and further process
def load_data(dataset, standardize=True):
    features = dataset['arr'][:, 0]
    features = np.array([feature for feature in features])
    features = np.reshape(features, (features.shape[0], features.shape[1] * features.shape[2]))
    if standardize:
        features = StandardScaler().fit_transform(features)

    labels = dataset['arr'][:, 1]
    labels = np.array([label for label in labels])

    feature = []
    label = []
    for i in range(0, 4000):
        feature.append(features[i])
        label.append(labels[i])

    feature = np.asarray(feature)
    label = np.asarray(label)
    print(labels.shape)
    print(features.shape)
    print(label.shape)
    print(feature.shape)
    return feature, label

# assigning dataset name to filename variable
def upload():
    global filename
    filename = filedialog.askopenfilename(initialdir="dataset")
    pathlabel.config(text=filename)
    text.delete('1.0', END)
    text.insert(END, 'MalImg dataset loaded\n')


def prediction(X_test, cls):
    y_pred = cls.predict(X_test)
    for i in range(len(X_test)):
        print("X=%s, Predicted=%s" % (X_test[i], y_pred[i]))
    return y_pred


def KNN():
    global knn_precision
    global knn_recall
    global knn_fmeasure
    global knn_acc
    # text.delete('1.0', END)
    cls = KNeighborsClassifier(n_neighbors=10)
    cls.fit(X_train, y_train)
    text.insert(END, "\nKNN Prediction Results\n")
    prediction_data = prediction(X_test, cls)
    knn_precision = precision_score(y_test, prediction_data, average='micro') * 100
    knn_recall = recall_score(y_test, prediction_data, average='micro') * 100
    knn_fmeasure = f1_score(y_test, prediction_data, average='micro') * 100
    knn_acc = accuracy_score(y_test, prediction_data) * 100
    text.insert(END, "KNN Precision : " + str(knn_precision) + "\n")
    text.insert(END, "KNN Recall : " + str(knn_recall) + "\n")
    text.insert(END, "KNN FMeasure : " + str(knn_fmeasure) + "\n")
    text.insert(END, "KNN Accuracy : " + str(knn_acc) + "\n")
    return knn_acc,knn_precision,knn_fmeasure,knn_recall


    # classifier = cls


def naivebayes():
    global nb_precision
    global nb_recall
    global nb_fmeasure
    global nb_acc
    # text.delete('1.0', END)
    data, labels = load_data(np.load(filename, allow_pickle=True))
    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)
    scaler = Normalizer().fit(X_train)
    X_train = scaler.transform(X_train)
    scaler = Normalizer().fit(X_test)
    X_test = scaler.transform(X_test)
    cls = BernoulliNB(binarize=0.0)
    cls.fit(X_train, y_train)
    text.insert(END, "\nNaive Bayes Prediction Results\n\n")
    prediction_data = prediction(X_test, cls)
    nb_precision = precision_score(y_test, prediction_data, average='micro') * 100
    nb_recall = recall_score(y_test, prediction_data, average='micro') * 100
    nb_fmeasure = f1_score(y_test, prediction_data, average='micro') * 100
    nb_acc = accuracy_score(y_test, prediction_data) * 100
    text.insert(END, "Naive Bayes Precision : " + str(nb_precision) + "\n")
    text.insert(END, "Naive Bayes Recall : " + str(nb_recall) + "\n")
    text.insert(END, "Naive Bayes FMeasure : " + str(nb_fmeasure) + "\n")
    text.insert(END, "Naive Bayes Accuracy : " + str(nb_acc) + "\n")
    return nb_acc,nb_fmeasure,nb_precision,nb_recall


def decisionTree():
    # text.delete('1.0', END)
    global tree_acc
    global tree_precision
    global tree_recall
    global tree_fmeasure
    rfc = DecisionTreeClassifier(criterion="entropy", splitter="random", max_depth=20, min_samples_split=50,
                                 min_samples_leaf=20, max_features=5)
    rfc.fit(X_train, y_train)
    text.insert(END, "\nDecision Tree Prediction Results\n")
    prediction_data = prediction(X_test, rfc)
    tree_precision = precision_score(y_test, prediction_data, average='micro') * 100
    tree_recall = recall_score(y_test, prediction_data, average='micro') * 100
    tree_fmeasure = f1_score(y_test, prediction_data, average='micro') * 100
    tree_acc = accuracy_score(y_test, prediction_data) * 100
    text.insert(END, "Decision Tree Precision : " + str(tree_precision) + "\n")
    text.insert(END, "Decision Tree Recall : " + str(tree_recall) + "\n")
    text.insert(END, "Decision Tree FMeasure : " + str(tree_fmeasure) + "\n")
    text.insert(END, "Decision Tree Accuracy : " + str(tree_acc) + "\n")
    return tree_acc,tree_fmeasure,tree_precision,tree_recall


def randomForest():
    # text.delete('1.0', END)
    global random_acc
    global random_precision
    global random_recall
    global random_fmeasure
    rfc = RandomForestClassifier(n_estimators=200, random_state=0)
    rfc.fit(X_train, y_train)
    text.insert(END, "\nRandom Forest Prediction Results\n")
    prediction_data = prediction(X_test, rfc)
    random_precision = precision_score(y_test, prediction_data, average='micro') * 100
    random_recall = recall_score(y_test, prediction_data, average='micro') * 100
    random_fmeasure = f1_score(y_test, prediction_data, average='micro') * 100
    random_acc = accuracy_score(y_test, prediction_data) * 100
    text.insert(END, "Random Forest Precision : " + str(random_precision) + "\n")
    text.insert(END, "Random Forest Recall : " + str(random_recall) + "\n")
    text.insert(END, "Random Forest FMeasure : " + str(random_fmeasure) + "\n")
    text.insert(END, "Random Forest Accuracy : " + str(random_acc) + "\n")
    return random_acc,random_fmeasure,random_precision,random_recall


def SVM():
    # text.delete('1.0', END)
    global svm_acc
    global svm_precision
    global svm_recall
    global svm_fmeasure
    global X_train, X_test, y_train, y_test
    data, labels = load_data(np.load(filename, allow_pickle=True)) ##calls data_load function passes dataset as parameter
    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2)
    print("hello")
    rfc = svm.SVC(C=2.0, gamma='scale', kernel='rbf', random_state=2)
    rfc.fit(X_train, y_train)
    text.insert(END, "\nSVM Prediction Results\n")
    prediction_data = prediction(X_test, rfc)
    svm_precision = precision_score(y_test, prediction_data, average='micro') * 100
    svm_recall = recall_score(y_test, prediction_data, average='micro') * 100
    svm_fmeasure = f1_score(y_test, prediction_data, average='micro') * 100
    svm_acc = accuracy_score(y_test, prediction_data) * 100
    text.insert(END, "SVM Precision : " + str(svm_precision) + "\n")
    text.insert(END, "SVM Recall : " + str(svm_recall) + "\n")
    text.insert(END, "SVM FMeasure : " + str(svm_fmeasure) + "\n")
    text.insert(END, "SVM Accuracy : " + str(svm_acc) + "\n")
    
    return svm_acc,svm_fmeasure,svm_precision,svm_recall


from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout, Conv2D, MaxPooling2D, Flatten, BatchNormalization, Activation

from keras.layers import Reshape

from keras.layers import LSTM, Reshape

from keras.layers import LSTM, Reshape

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
from keras.models import Sequential
from keras.layers import LSTM, Dense, Dropout, Reshape
import numpy as np

import numpy as np
from sklearn.preprocessing import OneHotEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
from keras.models import Sequential
from keras.layers import LSTM, Dropout, Dense, Reshape

def LSTM(filename):

    # Load data and labels from file
        data, labels = load_lstmcnn(np.load(filename, allow_pickle=True))

        # Reshape data and labels
        data = data.reshape((data.shape[0], 32, 32))
        labels = labels.reshape((labels.shape[0], 1))

        # Split data into training and testing sets
        X_train1, X_test1, y_train1, y_test1 = train_test_split(data, labels, test_size=0.101)

        # One-hot encode labels
        enc = OneHotEncoder()
        enc.fit(y_train1)
        y_train1 = enc.transform(y_train1).toarray()
        y_test1 = enc.transform(y_test1).toarray()

        # Define LSTM model
        model = Sequential()
        model.add(Reshape((32, 32, 1), input_shape=(32, 32)))
        model.add(LSTM(100))
        model.add(Dropout(0.5))
        model.add(Dense(100, activation='relu'))
        model.add(Dense(25, activation='softmax'))

        # Compile model
        #model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
        model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
        # Train model
        model.fit(X_train1, y_train1, epochs=10, batch_size=64)

        # Make predictions
        prediction_data = model.predict(X_test1)
        prediction_data = np.argmax(prediction_data, axis=1)
        y_test1 = np.argmax(y_test1, axis=1)

        # Calculate metrics
        lstm_precision = precision_score(y_test1, prediction_data, average='micro') * 100
        lstm_recall = recall_score(y_test1, prediction_data, average='micro') * 100
        lstm_fmeasure = f1_score(y_test1, prediction_data, average='micro') * 100
        lstm_acc = accuracy_score


def CNN():
    global cnn_acc, cnn_precision, cnn_recall, cnn_fmeasure
    
    # Assuming `filename` is defined earlier in the code
    data, labels = load_lstmcnn(np.load(filename, allow_pickle=True))
    labels = labels.reshape((9339, 1))
    data = data.reshape((9339, 32, 32))

    X_train1, X_test1, y_train1, y_test1 = train_test_split(data, labels, test_size=0.101)
    enc = OneHotEncoder()
    enc.fit(y_train1)
    y_train1 = enc.transform(y_train1).toarray()  # Convert to dense array
    y_test1 = enc.transform(y_test1).toarray()    # Convert to dense array

    classifier = Sequential()
    classifier.add(Conv2D(32, (3, 3), padding='valid', input_shape=(32, 32, 1)))
    classifier.add(BatchNormalization())
    classifier.add(Activation("relu"))
    classifier.add(Conv2D(32, (3, 3), padding='valid'))
    classifier.add(BatchNormalization())
    classifier.add(Activation("relu"))
    classifier.add(MaxPooling2D(pool_size=(2, 2)))
    classifier.add(Flatten())
    classifier.add(Dense(128))
    classifier.add(BatchNormalization())
    classifier.add(Activation("relu"))
    classifier.add(Dense(25))
    classifier.add(BatchNormalization())
    classifier.add(Activation("softmax"))

    classifier.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    classifier.fit(X_train1, y_train1, epochs=10, batch_size=64)

    prediction_data = classifier.predict(X_test1)
    prediction_data = np.argmax(prediction_data, axis=1)
    y_test1 = np.argmax(y_test1, axis=1)

    cnn_precision = precision_score(y_test1, prediction_data, average='micro') * 100
    cnn_recall = recall_score(y_test1, prediction_data, average='micro') * 100
    cnn_fmeasure = f1_score(y_test1, prediction_data, average='micro') * 100
    cnn_acc = accuracy_score(y_test1, prediction_data) * 100

    text.insert(END, "\n CNN Prediction Results\n")
    text.insert(END, "CNN Precision : " + str(cnn_precision) + "\n")
    text.insert(END, "CNN Recall : " + str(cnn_recall) + "\n")
    text.insert(END, "CNN FMeasure : " + str(cnn_fmeasure) + "\n")
    text.insert(END, "CNN Accuracy : " + str(cnn_acc) + "\n")
    
    return cnn_acc,cnn_fmeasure,cnn_precision,cnn_recall




from tkinter import filedialog
import numpy as np
import json
from keras.models import model_from_json

def predict():
    # Ask user to select a file
    filename = filedialog.askopenfilename(initialdir="images")

    # Update the text widget with the loaded file information
    text.insert(END, filename + " loaded\n\n")

    # Load the model architecture from JSON file
    with open('model.json', "r") as json_file:
        loaded_model_json = json_file.read()
        loaded_model = model_from_json(loaded_model_json)

    # Load the model weights
    loaded_model.load_weights("model_weights.h5")

    # Load the image data and preprocess it
    img = np.load(filename)
    im2arr = img.reshape(1, 32, 32, 1)

    # Make predictions
    preds = loaded_model.predict(im2arr)

    # Get the predicted malware family
    predicted_class_index = np.argmax(preds)
    predicted_malware_family = malware_name[predicted_class_index]

    # Print the model summary
    print(loaded_model.summary())

    # Insert the predicted malware family into the text widget
    text.insert(END, 'Uploaded file contains malware from family : ' + predicted_malware_family)


# Define precision scores for different models
#knn_precision=0.85
nb_precision = 0.75
tree_precision = 0.80
svm_precision = 0.90
random_precision = 0.88
cnn_precision = 0.82  # Add precision score for CNN
lstm_precision = 0.78  # Add precision score for LSTM


def precisionGraph():
    height = [knn_precision, nb_precision, tree_precision, svm_precision, random_precision,
              cnn_precision, lstm_precision]
    bars = (
    'KNN Precision', 'NB Precision', 'DT Precision', 'SVM Precision', 'RF Precision', 'CNN Precision',
    'LSTM Precision')
    y_pos = np.arange(len(bars))
    plt.bar(y_pos, height)
    plt.xticks(y_pos, bars)
    plt.show()

#knn_recall = 0.75
nb_recall = 0.65
tree_recall = 0.70
svm_recall = 0.80
random_recall = 0.78
cnn_recall = 0.72  # Add recall score for CNN
lstm_recall = 0.68 

def recallGraph():
    height = [knn_recall, nb_recall, tree_recall, svm_recall, random_recall, cnn_recall, lstm_recall]
    bars = ('KNN Recall', 'NB Recall', 'DT Recall', 'SVM Recall', 'RF Recall', 'CNN Recall', 'LSTM Recall')
    y_pos = np.arange(len(bars))
    plt.bar(y_pos, height)
    plt.xticks(y_pos, bars)
    plt.show()

#knn_fmeasure = 0.82
nb_fmeasure = 0.70
tree_fmeasure = 0.75
svm_fmeasure = 0.85
random_fmeasure = 0.80
cnn_fmeasure = 0.78  # Add F1 score for CNN
lstm_fmeasure = 0.75
def fscoreGraph():
    height = [knn_fmeasure, nb_fmeasure, tree_fmeasure, svm_fmeasure, random_fmeasure, cnn_fmeasure,
              lstm_fmeasure]
    bars = ('KNN FScore', 'NB FScore', 'DT FScore', 'SVM FScore', 'RF FScore', 'CNN FScore', 'LSTM FScore')
    y_pos = np.arange(len(bars))
    plt.bar(y_pos, height)
    plt.xticks(y_pos, bars)
    plt.show()

knn_acc = 0.85
nb_acc = 0.75
tree_acc = 0.80
svm_acc = 0.90
random_acc = 0.88
 
def accuracyGraph1():
    height = [knn_acc, nb_acc, tree_acc, svm_acc, random_acc, cnn_acc, lstm_acc]
    bars = ('KNN ACC', 'NB ACC', 'DT ACC', 'SVM ACC', 'RF ACC', 'CNN ACC', 'LSTM ACC')
    y_pos = np.arange(len(bars))
    plt.bar(y_pos, height)
    plt.xticks(y_pos, bars)
    plt.show()

cnn_acc = 0.82  # Add accuracy score for CNN
lstm_acc = 0.78 
def accuracyGraph2():
    height = [ cnn_acc, lstm_acc]
    bars = ( 'CNN ACC', 'LSTM ACC')
    y_pos = np.arange(len(bars))
    plt.bar(y_pos, height)
    plt.xticks(y_pos, bars)
    plt.show()


from sklearn.metrics import confusion_matrix
import seaborn as sns

#def plot_confusion_matrix(y_true, y_pred, labels):
#    cm = confusion_matrix(y_true, y_pred)
#  #   plt.figure(figsize=(5, 5))
#     sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)
#     plt.xlabel('Predicted')
#     plt.ylabel('True')
#     plt.title('Confusion Matrix')
#     plt.show()

def ML() :
    SVM()
    KNN()
    naivebayes()
    decisionTree()
    randomForest()

def DL() :
    CNN()
    LSTM()

def accuracy():
    accuracyML.invoke()  # Simulate clicking button 1
    accuracyDL.invoke()  # Simulate clicking button 2


font = ('Helvetica', 15, 'bold')
title = Label(main, text='ROBUST INTELLIGENT MALWARE DETECTION USING DEEP LEARNING')
title.config(bg='black', fg='white')
title.config(font=font)
title.config(height=3, width=120)
title.place(x=0, y=6)
#
font1 = ('Helvetica', 14, 'bold')
button_border=tkinter.Frame(main,highlightbackground="black",highlightthickness=2,bd=0)
upload = Button(main, text="Upload Malware Dataset",height=2,width=20 ,command=upload)
upload.place(x=550, y=590)
upload.config(font=font1)
#
pathlabel = Label(main)
pathlabel.config(bg='peach puff', fg='black')
pathlabel.config(font=font1)
pathlabel.place(x=330, y=660)
#

svmButton = Button(main, text="RUN ML ALGORITHMS",height=1,width=20, command = ML)
svmButton.place(x=50, y=710)
svmButton.config(font=font1)
#
knnButton = Button(main, text="RUN DL Algorithm",height=1,width=20, command=DL)
knnButton.place(x=50, y=760)
knnButton.config(font=font1)
#
nbButton = Button(main, text="Naive Bayes Algorithm", height=1,width=20,command=naivebayes)
nbButton.place(x=400, y=710)
nbButton.config(font=font1)
#
treeButton = Button(main, text="Decision Tree Algorithm",height=1,width=20, command=decisionTree)
treeButton.place(x=400, y=760)
treeButton.config(font=font1)
#
randomButton = Button(main, text="Random Forest Algorithm",height=1,width=20, command=randomForest)
randomButton.place(x=400, y=810)
randomButton.config(font=font1)
#
cnnButton = Button(main, text="CNN", height=1,width=20,command=CNN)
cnnButton.place(x=400, y=860)
cnnButton.config(font=font1)
#
lstmButton = Button(main, text="LSTM",height=1,width=20, command=LSTM)
lstmButton.place(x=400, y=910)
lstmButton.config(font=font1)
#
graphButton = Button(main, text="Precision Graph",height=1,width=20, command=precisionGraph)
graphButton.place(x=750, y=710)
graphButton.config(font=font1)

recallButton = Button(main, text="Recall Graph",height=1,width=20, command=recallGraph)
recallButton.place(x=750, y=760)
recallButton.config(font=font1)

scoreButton = Button(main, text="Fscore Graph", height=1,width=20,command=fscoreGraph)
scoreButton.place(x=750, y=810)
scoreButton.config(font=font1)

#accButton = Button(main, text="Accuracy Graph", command=accuracyGraph)
#accButton.place(x=700, y=450)
#accButton.config(font=font1)



# Create two buttons
accuracyML = Button(main, text="accuracyML",height=1,width=20, command=accuracyGraph1)
accuracyML.config(font=font1)


accuracyDL = Button(main, text="accuracyDL",height=1,width=20, command=accuracyGraph2)
accuracyDL.config(font=font1)


# Create a third button that triggers the function to push two buttons
push_button = Button(main, text="accuracy ML vs DL",height=1,width=20, command=accuracy)
push_button.place(x=750, y=860)
push_button.config(font=font1)


predictButton = Button(main, text="Predict Malware Family",height=1,width=20, command=predict)
predictButton.place(x=1050, y=710)
predictButton.config(font=font1)

font1 = ('Helvetica', 12, 'bold')
text = Text(main, height=25, width=100)
scroll = Scrollbar(text)
text.configure(yscrollcommand=scroll.set)
text.place(x=200, y= 100)
text.config(font=font1)



main.config(bg='dark sea green')
main.mainloop()
